{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpsons Haiku Demo \n",
    "## [@SimpsonsHaiku](https://twitter.com/SimpsonsHaiku)\n",
    "\n",
    "For anyone who knows me, they'll attest that The Simpsons has had an undue impact on my life, being formative through my early years and enduring to the present moment. That contribution spanned curating a sense of humour deeply anchored in an appreciation for the surreal, a continued love of animation, or exposure to the depths of obscure Americana (thank you, John Swartwzelder).\n",
    "\n",
    "This notebook demonstrates the implementation of an idea I had long ago, inspired by [@nythaikus](https://twitter.com/nythaikus). We start by loading the core haiku object, of class `SimpsonsHaiku`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import compuglobal\n",
    "from haiku import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 400995/400995 [00:07<00:00, 55386.07it/s]\n"
     ]
    }
   ],
   "source": [
    "simpsons_haiku = SimpsonsHaiku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = simpsons_haiku.script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ooo, careful, Homer.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script.spoken_words.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 224863/224863 [00:00<00:00, 917681.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([25369, 86, 69,\n",
       "       'Devil: Ahem! I hold here a contract between myself and one Homer Simpson, pledging me his soul for a donut. Which I delivered! And it was scrum-diddly-umptious!',\n",
       "       378000, True, 346.0, 25.0, 'Devil', 'Simpson Living Room',\n",
       "       'Ahem! I hold here a contract between myself and one Homer Simpson, pledging me his soul for a donut. Which I delivered! And it was scrum-diddly-umptious!',\n",
       "       'ahem i hold here a contract between myself and one homer simpson pledging me his soul for a donut which i delivered and it was scrum-diddly-umptious',\n",
       "       26.0, 86, 'Treehouse of Horror IV', 5, 86, 'Ahem', 1, 2],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "script[script.normalized_text.progress_apply(lambda x: 'diddly' in x)].iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>95633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i</td>\n",
       "      <td>81109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you</td>\n",
       "      <td>79846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>72057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>71689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42120</th>\n",
       "      <td>hippity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42121</th>\n",
       "      <td>hippo's</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42122</th>\n",
       "      <td>street's</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42123</th>\n",
       "      <td>hir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42124</th>\n",
       "      <td>larynx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42125 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  counts\n",
       "0           the   95633\n",
       "1             i   81109\n",
       "2           you   79846\n",
       "3             a   72057\n",
       "4                 71689\n",
       "...         ...     ...\n",
       "42120   hippity       1\n",
       "42121   hippo's       1\n",
       "42122  street's       1\n",
       "42123       hir       1\n",
       "42124    larynx       1\n",
       "\n",
       "[42125 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = script['spoken_words'].str.cat(sep=' ')\n",
    "for char in [\",\", \".\", \"?\", \"!\", \":\", \"\\\\\", \"\\\"\"]:#self.strip_list:\n",
    "    corpus = corpus.replace(char, '')\n",
    "corpus_list = corpus.lower().replace('-', ' ').replace('/', ' ').split(' ')\n",
    "\n",
    "corpus_df = pd.DataFrame({'word' : corpus_list})\n",
    "\n",
    "simpsons_count = corpus_df.value_counts().reset_index(name='counts')\n",
    "simpsons_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('simpson_lect.json', orient='index').reset_index().rename({'index':'word', 0:'n_syllable'}, axis=1)\n",
    "df['syllables_estimate'] = df.word.apply(syllables.estimate)\n",
    "df['syllapy_estimate'] = df.word.apply(syllapy.count)\n",
    "\n",
    "df['syllables_error'] = abs(df.word.apply(syllables.estimate) - df['n_syllable'])\n",
    "df['syllapy_error'] = abs(df.word.apply(syllapy.count) - df['n_syllable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_syllable</th>\n",
       "      <th>syllables_estimate</th>\n",
       "      <th>syllapy_estimate</th>\n",
       "      <th>syllables_error</th>\n",
       "      <th>syllapy_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.908297</td>\n",
       "      <td>1.802038</td>\n",
       "      <td>1.679767</td>\n",
       "      <td>0.251820</td>\n",
       "      <td>0.283843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.844484</td>\n",
       "      <td>0.826913</td>\n",
       "      <td>0.865224</td>\n",
       "      <td>0.560398</td>\n",
       "      <td>0.669679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n_syllable  syllables_estimate  syllapy_estimate  syllables_error  \\\n",
       "mean    1.908297            1.802038          1.679767         0.251820   \n",
       "std     0.844484            0.826913          0.865224         0.560398   \n",
       "\n",
       "      syllapy_error  \n",
       "mean       0.283843  \n",
       "std        0.669679  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing syllables and syllapy performance on labelled syllable set\n",
    "df.describe().iloc[1:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate haiku_df, will do so from scratch here but will load from path if it is passed when instantiating SimpsonsHaiku object.\n",
    "# haiku_df = simpsons_haiku.generate_haiku_df(save=True)\n",
    "# haiku_df.sample().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████▋                  | 168642/224863 [09:39<02:57, 317.61it/s]"
     ]
    }
   ],
   "source": [
    "haiku, _ = simpsons_haiku.generate_haiku()\n",
    "print(haiku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpsons_haiku.generate_haiku()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of lines of dialogue in a 17-syllable sequence? It's 16 (3 men and a comic book)\n",
    "haiku_df['n_lines'] = haiku_df.number.apply(len)\n",
    "haiku_df[haiku_df.n_lines == haiku_df.n_lines.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of unique characters in a 17-syllable sequence? It's Homer 3D, with 9 characters. Did anyone see the movie Tron?\n",
    "haiku_df['n_characters'] = haiku_df.character_id.apply(lambda x: len(set(x)))\n",
    "haiku_df[haiku_df.n_characters == haiku_df.n_characters.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about locations?\n",
    "haiku_df['n_locations'] = haiku_df.location_id.apply(lambda x: len(set(x)))\n",
    "haiku_df[haiku_df.n_locations == haiku_df.n_locations.max()].spoken_words_split.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution by Season\n",
    "# haiku_df.season.value_counts().plot(kind='bar')\n",
    "haiku_df.groupby('season').count()['id_x'].plot()\n",
    "plt.title('Number of haikus per season')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which episode(s) have the most haikus?\n",
    "haiku_df.reset_index().groupby('episode_id').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_script = pd.read_csv('dataset/simpsons_script_lines.csv', error_bad_lines=False).dropna(subset=['word_count'])\n",
    "episode_data = pd.read_csv('dataset/simpsons_episodes.csv')[['id', 'title', 'season', 'number_in_series']]\n",
    "base_script = pd.merge(base_script, episode_data, how='left', left_on='episode_id', right_on='id')\n",
    "\n",
    "base_script['n_syllables'] = base_script.spoken_words.progress_apply(simpsons_haiku.count_syllables_line)\n",
    "base_script.groupby('season')['n_syllables'].mean().plot(label='Mean syllables per line')\n",
    "base_script.groupby('season')['word_count'].mean().plot(label='Mean words per line')\n",
    "\n",
    "plt.title('Mean number of words per line by season (Original script)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This the ratio of the two lines above\n",
    "plt.title('Mean number of syllables per word by season')\n",
    "(base_script.groupby('season')['n_syllables'].sum() / base_script.groupby('season')['word_count'].sum()).plot(color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the longest lines\n",
    "long_script = script[script.n_syllables > 17]\n",
    "# long_script.sort_values('n_syllables', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution by syllable count\n",
    "haiku_df.n_syllables.value_counts()#.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher quality haikus\n",
    "haiku_array = haiku_df[haiku_df.n_syllables.apply(lambda x: (x == [5, 7, 5]) | (x == [17]) | (x == [5, 12])| (x == [12, 5]))].sample().spoken_words_split.values# Search for [17], [5, 7, 5], [5, 12], [12, 5]\n",
    "haiku_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_df[haiku_df.n_syllables.apply(lambda x: ((x != [5, 7, 5]) & (x != [17]) & (x != [5, 12]) & (x != [12, 5])))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medium quality?\n",
    "haiku_df[haiku_df.n_syllables.apply(lambda x: x == [7, 5, 5])].sample().spoken_words_split.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower quality haikus\n",
    "haiku_df[haiku_df.n_syllables.apply(lambda x: ((x != [5, 7, 5]) & (x != [17]) & (x != [5, 12]) & (x != [12, 5])))].sample().spoken_words_split.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "simpsons = compuglobal.Frinkiac()\n",
    "haiku_array = [\"It doesn't take a whiz to see that you're looking out for number one\"]\n",
    "# Search\n",
    "screencap = simpsons.search_for_screencap(haiku_array[0])\n",
    "\n",
    "# Images/Gifs\n",
    "image = screencap.get_meme_url()\n",
    "gif = screencap.get_gif_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in \"Perhaps I may be of help Where did you come from I'm your cellmate\".split():\n",
    "    print(word, simpsons_haiku.num_syllables(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_script[base_script.spoken_words.apply(lambda x: 'TV' in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simpsons_haiku",
   "language": "python",
   "name": "simpsons_haiku"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "41912a6cf46c57c1e23829e836fc30eac55f9e23ffe2f84c53dcbcab27e0fc59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
